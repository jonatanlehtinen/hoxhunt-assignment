{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoxHunt Summer Hunters 2021 - Data - Home assignment\n",
    "\n",
    "\n",
    "<img src=\"http://hunters.hoxhunt.com/public/hero.svg\" width=\"800\">\n",
    "\n",
    "## Assignment\n",
    "\n",
    "In this assignment you as a HoxHunt Data Science Hunter are given the task to extract interesting features from a possible malicious indicator of compromise, more specifically in this case from a given potentially malicious URL. \n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/ao0neaphtfama7g/Screenshot%202019-03-21%2017.23.40.png?dl=1\" width=\"400\">\n",
    "\n",
    "This assignment assumes that you are comfortable (or quick to learn) on using Jupyter Notebooks and Python. You are free to use any external libraries you wish. We have included an example below using the Requests library.\n",
    "\n",
    "Happy hunting!\n",
    "\n",
    "\n",
    "## Interesting research papers & resources\n",
    "\n",
    "Below is a list of interesting research papers on the topic. They might give you good tips what features you could extract from a given URL:\n",
    "\n",
    "\n",
    "[Know Your Phish: Novel Techniques for Detecting\n",
    "Phishing Sites and their Targets](https://arxiv.org/pdf/1510.06501.pdf)\n",
    "\n",
    "[DeltaPhish: Detecting Phishing Webpages\n",
    "in Compromised Websites](https://arxiv.org/pdf/1707.00317.pdf)\n",
    "\n",
    "[PhishAri: Automatic Realtime Phishing Detection on Twitter](https://arxiv.org/pdf/1301.6899.pdf)\n",
    "\n",
    "[More or Less? Predict the Social Influence of Malicious URLs on Social Media\n",
    "](https://arxiv.org/abs/1812.02978)\n",
    "\n",
    "[awesome-threat-intelligence](https://github.com/hslatman/awesome-threat-intelligence)\n",
    "\n",
    "\n",
    "\n",
    "## What we expect\n",
    "\n",
    "Investigate potential features you could extract from a given URL, and implement extractors for the ones that interest you the most. The example code below extracts one feature, but does not store it very efficiently (just console logs it). Implement a sensible data structure using some known data structure library to store the features per URL. Choose one feature for which you can visualise the results. What does the visualisation tell you? Also consider how you would approach error handling, if one of the feature extractor fails?\n",
    "\n",
    "Should you make it to the next stage, be prepared to discuss the following topics: what features could indicate the malicousness of a given URL? What goes in to the thinking of the attacker when they are choosing a site for an attack? What inspired your solution and what would you develop next?\n",
    "\n",
    "## What we don't expect\n",
    "\n",
    "- That you implement a humangous set of features.\n",
    "- That you implement any kind of actual predicition models that uses the features to give predictions on malicousness at this stage.\n",
    "\n",
    "## Tips \n",
    "\n",
    "\n",
    "- Keep it tidy - a human is going to asses your work :)\n",
    "- Ensure your program does not contain any unwanted behaviour\n",
    "- What makes your solution stand out from the crowd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.slideshare.net/weaveworks/client-side-monitoring-with-prometheus 5423\n",
      "https://intezasanpaolo.com/ 4\n",
      "http://sec-login-device.com/ 5\n",
      "http://college-eisk.ru/cli/ 3405\n",
      "https://dotpay-platnosc3.eu/dotpay/ None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_domain_age_in_days(domain):\n",
    "    show = \"https://input.payapi.io/v1/api/fraud/domain/age/\" + domain\n",
    "    data = requests.get(show).json()\n",
    "    return data['result'] if 'result' in data else None\n",
    "\n",
    "def parse_domain_from_url(url):\n",
    "    t = urlparse(url).netloc\n",
    "    return '.'.join(t.split('.')[-2:])\n",
    "\n",
    "def analyze_url(url):\n",
    "    # First feature, if domain is new it could indicate that the bad guy has bought it recently...\n",
    "    age_in_days_feature = get_domain_age_in_days(parse_domain_from_url(url));\n",
    "    # Hmm...maybe I could do something more sensible with the data than just printing out\n",
    "    print(url, age_in_days_feature)\n",
    "\n",
    "# Note some of these urls are live phishing sites (as of 2021-02-05) use with caution! More can be found at https://www.phishtank.com/\n",
    "example_urls = [\"https://www.slideshare.net/weaveworks/client-side-monitoring-with-prometheus\",\n",
    "                \"https://intezasanpaolo.com/\",\n",
    "                \"http://sec-login-device.com/\",\n",
    "                \"http://college-eisk.ru/cli/\",\n",
    "                \"https://dotpay-platnosc3.eu/dotpay/\"\n",
    "               ]\n",
    "for url in example_urls: \n",
    "    analyze_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "hoxhuntenv",
   "language": "python",
   "name": "hoxhuntenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
